{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and testing grounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, pylab, pandas as pd\n",
    "import pydicom, numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation Functions\n",
    "\n",
    "Writing multiple functions to facilitate creating different datasets, modeling over different datasets and/or different hyperparameters, and evaluating the different models using graphs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PnemoniaTargetMapIsWeird(AssertionError):\n",
    "    \"\"\"Raise this when the target is not mapped to 2 or 3 outputs\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pic_df(data, df_detailed, image_size = (128,128)):\n",
    "    \n",
    "    print('---Enter DataFrame Construction Function---')\n",
    "    \n",
    "    ## Data Prep\n",
    "    # Need to define df_detailed somewhere\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    merged_df = df_detailed.merge(data, on='patientId')\n",
    "    \n",
    "    print('---Create Pixel Array Labels---')\n",
    "    \n",
    "    # Create the column labels for the pixel arrays\n",
    "    pixel_labels = []\n",
    "    for i in range(image_size[0] * image_size[1]):\n",
    "        pixel_labels.append(\"pixel\"+str(i))\n",
    "    \n",
    "    print('---Create Total Pixel Array---')\n",
    "    \n",
    "    # Create the total pixel array\n",
    "    huge_pixel_array = []\n",
    "    for o in tqdm_notebook(range(merged_df.shape[0])):\n",
    "        # Get the image data\n",
    "        patientId = merged_df.iloc[o]['patientId']\n",
    "        dcm_file = '../data/stage_1_train_images/%s.dcm' % patientId\n",
    "        dcm_data = pydicom.read_file(dcm_file)\n",
    "        im = dcm_data.pixel_array\n",
    "\n",
    "        # Convert the image into a 1d array of pixels\n",
    "        curr_pixel_array = []\n",
    "        for i in resize(im, image_size): \n",
    "            curr_pixel_array.extend(i)\n",
    "        huge_pixel_array.append(curr_pixel_array)\n",
    "\n",
    "    print('---Create Dataframe---')\n",
    "        \n",
    "    # Creating the DataFrame\n",
    "    temp = pd.DataFrame(data = huge_pixel_array, columns = pixel_labels)\n",
    "    temp['class'] = merged_df['class']\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, model_name = \"default_model_name\", image_size = (128,128), y_map = {\n",
    "    \"Lung Opacity\":1,\n",
    "    \"No Lung Opacity / Not Normal\":0,\n",
    "    \"Normal\":2\n",
    "}, EPOCHS = 20, train_size = 0.75, metrics = ['accuracy'] ):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (Pandas DataFrame): cols=['class', all of the pixel data]\n",
    "        \n",
    "        model_name (str): The name with which to save the model\n",
    "        \n",
    "        image_size (touple: (int,int)): The width and height in pixels to scale the images. Max 1024x1024. This might be more finickey that I would've thought.\n",
    "        \n",
    "        y_map (dict): A dictionary mapping the target values to integers (0-?)\n",
    "        \n",
    "    Returns:\n",
    "        Keras Model fit on the data.\n",
    "        Saves the model to ../data/models/model_name datetime.h5\n",
    "    \"\"\"\n",
    "    print('---Enter Function---')\n",
    "    \n",
    "\n",
    "    # Create target\n",
    "    y = data['class']\n",
    "    y = y.map(lambda x: y_map[x])\n",
    "    \n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(columns='class'), y, \n",
    "                                                        stratify=y, random_state=42, train_size = train_size)\n",
    "    \n",
    "    # Transform target into arrays of integers\n",
    "    y_train_c = to_categorical(y_train)\n",
    "    y_test_c = to_categorical(y_test)\n",
    "    \n",
    "    # Reshape the X_train and X_test \n",
    "    X_train_re = X_train.values.reshape(X_train.shape[0], image_size[0], image_size[1], 1)\n",
    "    X_test_re = X_test.values.reshape(X_test.shape[0], image_size[0], image_size[1], 1)\n",
    "    \n",
    "    print('---Modeling---')\n",
    "    \n",
    "    ## Modeling\n",
    "    # Initialize Model\n",
    "    model_convolutional = Sequential()\n",
    "\n",
    "    # First Conv / Pool \n",
    "    model_convolutional.add(Conv2D(filters = 6,\n",
    "                                   kernel_size = 3,\n",
    "                                   activation = 'relu',\n",
    "                                   input_shape = (image_size[0], image_size[1], 1)\n",
    "                                  ))\n",
    "    model_convolutional.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Second Conv/ Pool\n",
    "    model_convolutional.add(Conv2D(filters=16, kernel_size=3, \n",
    "                                   activation='relu'))\n",
    "    model_convolutional.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Flatten\n",
    "    model_convolutional.add(Dropout(0.8))\n",
    "    model_convolutional.add(Flatten())\n",
    "\n",
    "    # Densely Connected Layers\n",
    "    model_convolutional.add(Dense(512, activation='relu'))\n",
    "    model_convolutional.add(Dropout(0.5))\n",
    "    model_convolutional.add(Dense(128, activation='relu'))\n",
    "    model_convolutional.add(Dropout(0.5))\n",
    "    \n",
    "    # Output Layer\n",
    "    if len(set(y_map.values())) == 3:\n",
    "        model_convolutional.add(Dense(3, activation='softmax'))\n",
    "    elif len(set(y_map.values())) == 2:\n",
    "        model_convolutional.add(Dense(2, activation='softmax'))\n",
    "    else:\n",
    "        raise PnemoniaTargetMapIsWeird(\"target is not mapped to 2 or 3 outputs\")\n",
    "\n",
    "\n",
    "    model_convolutional.compile(loss = 'categorical_crossentropy', \n",
    "                            optimizer = 'adam', \n",
    "                            metrics = metrics)\n",
    "    \n",
    "    # Train Model\n",
    "    trained_convolutional = model_convolutional.fit(X_train_re,\n",
    "                        y_train_c,\n",
    "                        batch_size = 32,\n",
    "                        epochs = EPOCHS,\n",
    "                        verbose = 1,\n",
    "                        validation_data = (X_test_re, y_test_c)\n",
    "                       )\n",
    "\n",
    "    # Save Model \n",
    "    try:\n",
    "        file_name = '../data/models/' + model_name + ' ' + str(datetime.datetime.now()) + '.h5'\n",
    "        \n",
    "        model_convolutional.save(file_name)\n",
    "        print('Model saved as: ' + file_name)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Model did not save.')\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "    return trained_convolutional, model_convolutional, file_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function that displays pertinant information regarding the quality of the model\n",
    "\n",
    "def evaluate_model (model, model_name = 'default', size=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: A trained model with \n",
    "        \n",
    "    Output:\n",
    "        Returns nothing. Prints out - plots comparing test set with training set on \n",
    "        each of the metrics (minimum: loss).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # checking out the different classes in the testing case and predictions\n",
    "    \n",
    "    # confusion matrix?\n",
    "    \n",
    "    keys=[]\n",
    "    for i in model.history.keys():\n",
    "        if i[0:3] != 'val':\n",
    "            keys.append(i)\n",
    "    \n",
    "    fig, ax = plt.subplots(len(keys), 1, figsize = (size, size*len(keys))) \n",
    "    fig.suptitle('Model: ' + model_name)\n",
    "    \n",
    "    index = 0\n",
    "    for i in keys:\n",
    "        # Plot of the Loss for the train and testingsets\n",
    "        ax[index].plot(model.history[i], label=i.capitalize())\n",
    "        ax[index].plot(model.history['val_'+i], label='Val '+i.capitalize())\n",
    "        ax[index].legend()\n",
    "        ax[index].set_title(i.capitalize()[15:-2], )\n",
    "        index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some initial modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Lung Opacity / Not Normal    11083\n",
       "Lung Opacity                     8383\n",
       "Normal                           8071\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Lung Opacity == Pneumonia\n",
    "y_map_3 = { # Normal, Pneumonia, or not normal but not pneumonia\n",
    "    \"Lung Opacity\":1,\n",
    "    \"No Lung Opacity / Not Normal\":0,\n",
    "    \"Normal\":2\n",
    "}\n",
    "\n",
    "y_map_2 = { # Either Pneumonia or Not Pneumonia\n",
    "    \"Lung Opacity\":1,\n",
    "    \"No Lung Opacity / Not Normal\":0,\n",
    "    \"Normal\":0\n",
    "}\n",
    "\n",
    "adult_data = pd.read_csv('../data/adult_patient_data.csv')\n",
    "df_detailed = pd.read_csv('../data/stage_1_detailed_class_info.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Parameters\n",
    "CURR_MAP = y_map_3\n",
    "model_name = 'adult_data_2_options'\n",
    "NUM_IMAGES = 6000 #pic_df.shape[0]\n",
    "EPOCHS = 20\n",
    "IMAGE_SIZE = (128,128)\n",
    "TRAIN_SIZE = 0.8\n",
    "METRICS = ['accuracy']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Enter DataFrame Construction Function---\n",
      "---Create Pixel Array Labels---\n",
      "---Create Total Pixel Array---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11488faad37c4fc19c9143a9221a9fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27537), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/ec2-user/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Create Dataframe---\n",
      "CPU times: user 8min 33s, sys: 15 s, total: 8min 48s\n",
      "Wall time: 8min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pic_df = create_pic_df(adult_data, df_detailed=df_detailed, image_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Enter Function---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Modeling---\n",
      "Train on 4800 samples, validate on 1200 samples\n",
      "Epoch 1/20\n",
      "4800/4800 [==============================] - 27s 6ms/step - loss: 1.0002 - acc: 0.4894 - val_loss: 0.8952 - val_acc: 0.5650\n",
      "Epoch 2/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.8920 - acc: 0.5681 - val_loss: 0.8448 - val_acc: 0.6033\n",
      "Epoch 3/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.8616 - acc: 0.5852 - val_loss: 0.8254 - val_acc: 0.6150\n",
      "Epoch 4/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.8427 - acc: 0.5996 - val_loss: 0.8054 - val_acc: 0.6108\n",
      "Epoch 5/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.8229 - acc: 0.6152 - val_loss: 0.8238 - val_acc: 0.6133\n",
      "Epoch 6/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.8069 - acc: 0.6200 - val_loss: 0.8188 - val_acc: 0.6242\n",
      "Epoch 7/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.7943 - acc: 0.6302 - val_loss: 0.8056 - val_acc: 0.6275\n",
      "Epoch 8/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.7735 - acc: 0.6333 - val_loss: 0.8076 - val_acc: 0.6292\n",
      "Epoch 9/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.7683 - acc: 0.6375 - val_loss: 0.8016 - val_acc: 0.6200\n",
      "Epoch 10/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.7488 - acc: 0.6527 - val_loss: 0.8146 - val_acc: 0.6283\n",
      "Epoch 11/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.7310 - acc: 0.6587 - val_loss: 0.7951 - val_acc: 0.6333\n",
      "Epoch 12/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.7218 - acc: 0.6746 - val_loss: 0.8156 - val_acc: 0.6358\n",
      "Epoch 13/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.6998 - acc: 0.6779 - val_loss: 0.8038 - val_acc: 0.6367\n",
      "Epoch 14/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.6815 - acc: 0.6892 - val_loss: 0.7968 - val_acc: 0.6308\n",
      "Epoch 15/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.6648 - acc: 0.6994 - val_loss: 0.7757 - val_acc: 0.6500\n",
      "Epoch 16/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.6563 - acc: 0.7048 - val_loss: 0.7968 - val_acc: 0.6425\n",
      "Epoch 17/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.6152 - acc: 0.7273 - val_loss: 0.8302 - val_acc: 0.6483\n",
      "Epoch 18/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.6229 - acc: 0.7225 - val_loss: 0.7921 - val_acc: 0.6433\n",
      "Epoch 19/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.6029 - acc: 0.7315 - val_loss: 0.7816 - val_acc: 0.6483\n",
      "Epoch 20/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.5780 - acc: 0.7444 - val_loss: 0.7978 - val_acc: 0.6600\n",
      "Model saved as: ../data/models/adult_data_2_options 2018-10-16 22:46:23.821897.h5\n",
      "CPU times: user 36min 44s, sys: 11min 34s, total: 48min 19s\n",
      "Wall time: 8min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "test_model_history, test_model_real, most_recent_model_name = model(pic_df.head(NUM_IMAGES), model_name = model_name, image_size=IMAGE_SIZE, y_map=CURR_MAP, EPOCHS=EPOCHS, train_size = TRAIN_SIZE, metrics = METRICS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b0118789a316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_pickle_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models.pk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfile_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pickle_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "models[most_recent_model_name] = {\n",
    "    'NUM_IMAGES':NUM_IMAGES,\n",
    "    'history':test_model_history,\n",
    "    'EPOCHS':EPOCHS,\n",
    "    'IMAGE_SIZE':IMAGE_SIZE,\n",
    "    'Y_MAP':CURR_MAP,\n",
    "    'TRAIN_SIZE':TRAIN_SIZE\n",
    "}\n",
    "\n",
    "# Save the list of models and parameters \n",
    "model_pickle_file_name = 'models.pk'\n",
    "file_object = open(model_pickle_file_name,'wb')\n",
    "pickle.dump(models, file_object)\n",
    "file_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(test_model_history, most_recent_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 21s, sys: 11.8 s, total: 4min 33s\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = pic_df.drop(columns='class')\n",
    "pred_x = X.values.reshape(X.shape[0], IMAGE_SIZE[0], IMAGE_SIZE[1], 1)\n",
    "preds = test_model_real.predict(pred_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = pic_df['class']\n",
    "y_real = to_categorical(y_real.map(lambda x: CURR_MAP[x]))\n",
    "y_real.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'../data/models/adult_data_3options 2018-10-16 20:49:23.542213.h5': {'NUM_IMAGES': 6000,\n",
       "  'history': <keras.callbacks.History at 0x7f06f81bf7f0>,\n",
       "  'EPOCHS': 20,\n",
       "  'IMAGE_SIZE': (128, 128),\n",
       "  'Y_MAP': {'Lung Opacity': 0,\n",
       "   'No Lung Opacity / Not Normal': 1,\n",
       "   'Normal': 1}},\n",
       " '../data/models/adult_data_2_options 2018-10-16 21:26:28.869268.h5': {'NUM_IMAGES': 6000,\n",
       "  'history': <keras.callbacks.History at 0x7f06fbe75390>,\n",
       "  'EPOCHS': 20,\n",
       "  'IMAGE_SIZE': (128, 128),\n",
       "  'Y_MAP': {'Lung Opacity': 1, 'No Lung Opacity / Not Normal': 0, 'Normal': 0},\n",
       "  'TRAIN_SIZE': 0.8},\n",
       " '../data/models/adult_data_2_options 2018-10-16 21:37:38.370253.h5': {'NUM_IMAGES': 6000,\n",
       "  'history': <keras.callbacks.History at 0x7f0676b494a8>,\n",
       "  'EPOCHS': 20,\n",
       "  'IMAGE_SIZE': (128, 128),\n",
       "  'Y_MAP': {'Lung Opacity': 1, 'No Lung Opacity / Not Normal': 0, 'Normal': 2},\n",
       "  'TRAIN_SIZE': 0.8}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the list of models/parameters\n",
    "\n",
    "model_pickle_file_name = 'models.pk'\n",
    "file_object = open(model_pickle_file_name,'r')\n",
    "\n",
    "models = pickle.load(file_object)\n",
    "file_object.close()\n",
    "\n",
    "display(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What am I trying to do now?\n",
    "- see if I can save the layers / meta information about each model so if I change it I know what model does well\n",
    "- start changing models around potentially using \n",
    "    - Stochastic gradient descent\n",
    "    - [R-CNN (or a different iteration)](https://heartbeat.fritz.ai/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b)\n",
    "    - [SpatialDropout2D](https://keras.io/layers/core/#spatialdropout2d)\n",
    "- increase font on plot super title, make sure that the super title even works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
