{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and testing grounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob, pylab, pandas as pd\n",
    "import pydicom, numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation Functions\n",
    "\n",
    "Writing multiple functions to facilitate creating different datasets, modeling over different datasets and/or different hyperparameters, and evaluating the different models using graphs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PnemoniaTargetMapIsWeird(AssertionError):\n",
    "    \"\"\"Raise this when the target is not mapped to 2 or 3 outputs\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pic_df(data, df_detailed, image_size = (128,128)):\n",
    "    \n",
    "    print('---Enter DataFrame Construction Function---')\n",
    "    \n",
    "    ## Data Prep\n",
    "    # Need to define df_detailed somewhere\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    merged_df = df_detailed.merge(data, on='patientId')\n",
    "    \n",
    "    print('---Create Pixel Array Labels---')\n",
    "    \n",
    "    # Create the column labels for the pixel arrays\n",
    "    pixel_labels = []\n",
    "    for i in range(image_size[0] * image_size[1]):\n",
    "        pixel_labels.append(\"pixel\"+str(i))\n",
    "    \n",
    "    print('---Create Total Pixel Array---')\n",
    "    \n",
    "    # Create the total pixel array\n",
    "    huge_pixel_array = []\n",
    "    for o in tqdm_notebook(range(merged_df.shape[0])):\n",
    "        # Get the image data\n",
    "        patientId = merged_df.iloc[o]['patientId']\n",
    "        dcm_file = '../data/stage_1_train_images/%s.dcm' % patientId\n",
    "        dcm_data = pydicom.read_file(dcm_file)\n",
    "        im = dcm_data.pixel_array\n",
    "\n",
    "        # Convert the image into a 1d array of pixels\n",
    "        curr_pixel_array = []\n",
    "        for i in resize(im, image_size): \n",
    "            curr_pixel_array.extend(i)\n",
    "        huge_pixel_array.append(curr_pixel_array)\n",
    "\n",
    "    print('---Create Dataframe---')\n",
    "        \n",
    "    # Creating the DataFrame\n",
    "    temp = pd.DataFrame(data = huge_pixel_array, columns = pixel_labels)\n",
    "    temp['class'] = merged_df['class']\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, model_name = \"default_model_name\", image_size = (128,128), y_map = {\n",
    "    \"Lung Opacity\":1,\n",
    "    \"No Lung Opacity / Not Normal\":0,\n",
    "    \"Normal\":2\n",
    "}, EPOCHS = 20, train_size = 0.75, metrics = ['accuracy'] ):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (Pandas DataFrame): cols=['class', all of the pixel data]\n",
    "        \n",
    "        model_name (str): The name with which to save the model\n",
    "        \n",
    "        image_size (touple: (int,int)): The width and height in pixels to scale the images. Max 1024x1024. This might be more finickey that I would've thought.\n",
    "        \n",
    "        y_map (dict): A dictionary mapping the target values to integers (0-?)\n",
    "        \n",
    "    Returns:\n",
    "        Keras Model fit on the data.\n",
    "        Saves the model to ../data/models/model_name datetime.h5\n",
    "    \"\"\"\n",
    "    print('---Enter Function---')\n",
    "    \n",
    "\n",
    "    # Create target\n",
    "    y = data['class']\n",
    "    y = y.map(lambda x: y_map[x])\n",
    "    \n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(columns='class'), y, \n",
    "                                                        stratify=y, random_state=42, train_size = train_size)\n",
    "    \n",
    "    # Transform target into arrays of integers\n",
    "    y_train_c = to_categorical(y_train)\n",
    "    y_test_c = to_categorical(y_test)\n",
    "    \n",
    "    # Reshape the X_train and X_test \n",
    "    X_train_re = X_train.values.reshape(X_train.shape[0], image_size[0], image_size[1], 1)\n",
    "    X_test_re = X_test.values.reshape(X_test.shape[0], image_size[0], image_size[1], 1)\n",
    "    \n",
    "    print('---Modeling---')\n",
    "    \n",
    "    ## Modeling\n",
    "    # Initialize Model\n",
    "    model_convolutional = Sequential()\n",
    "\n",
    "    # First Conv / Pool \n",
    "    model_convolutional.add(Conv2D(filters = 6,\n",
    "                                   kernel_size = 3,\n",
    "                                   activation = 'relu',\n",
    "                                   input_shape = (image_size[0], image_size[1], 1)\n",
    "                                  ))\n",
    "    model_convolutional.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Second Conv/ Pool\n",
    "    model_convolutional.add(Conv2D(filters=16, kernel_size=3, \n",
    "                                   activation='relu'))\n",
    "    model_convolutional.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Flatten\n",
    "    model_convolutional.add(Dropout(0.8))\n",
    "    model_convolutional.add(Flatten())\n",
    "\n",
    "    # Densely Connected Layers\n",
    "    model_convolutional.add(Dense(512, activation='relu'))\n",
    "    model_convolutional.add(Dropout(0.5))\n",
    "    model_convolutional.add(Dense(128, activation='relu'))\n",
    "    model_convolutional.add(Dropout(0.5))\n",
    "    \n",
    "    # Output Layer\n",
    "    if len(set(y_map.values())) == 3:\n",
    "        model_convolutional.add(Dense(3, activation='softmax'))\n",
    "    elif len(set(y_map.values())) == 2:\n",
    "        model_convolutional.add(Dense(2, activation='softmax'))\n",
    "    else:\n",
    "        raise PnemoniaTargetMapIsWeird(\"target is not mapped to 2 or 3 outputs\")\n",
    "\n",
    "\n",
    "    model_convolutional.compile(loss = 'categorical_crossentropy', \n",
    "                            optimizer = 'adam', \n",
    "                            metrics = metrics)\n",
    "    \n",
    "    # Train Model\n",
    "    trained_convolutional = model_convolutional.fit(X_train_re,\n",
    "                        y_train_c,\n",
    "                        batch_size = 32,\n",
    "                        epochs = EPOCHS,\n",
    "                        verbose = 1,\n",
    "                        validation_data = (X_test_re, y_test_c)\n",
    "                       )\n",
    "\n",
    "    # Save Model \n",
    "    try:\n",
    "        file_name = '../data/models/' + model_name + ' ' + str(datetime.datetime.now()) + '.h5'\n",
    "        \n",
    "        model_convolutional.save(file_name)\n",
    "        print('Model saved as: ' + file_name)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Model did not save.')\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "    return trained_convolutional, model_convolutional, file_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function that displays pertinant information regarding the quality of the model\n",
    "\n",
    "def evaluate_model (model, model_name = 'default', size=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: A trained model with \n",
    "        \n",
    "    Output:\n",
    "        Returns nothing. Prints out - plots comparing test set with training set on \n",
    "        each of the metrics (minimum: loss).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # checking out the different classes in the testing case and predictions\n",
    "    \n",
    "    # confusion matrix?\n",
    "    \n",
    "    keys=[]\n",
    "    for i in model.history.keys():\n",
    "        if i[0:3] != 'val':\n",
    "            keys.append(i)\n",
    "    \n",
    "    fig, ax = plt.subplots(len(keys), 1, figsize = (size, size*len(keys))) \n",
    "    fig.suptitle('Model: ' + model_name)\n",
    "    \n",
    "    index = 0\n",
    "    for i in keys:\n",
    "        # Plot of the Loss for the train and testingsets\n",
    "        ax[index].plot(model.history[i], label=i.capitalize())\n",
    "        ax[index].plot(model.history['val_'+i], label='Val '+i.capitalize())\n",
    "        ax[index].legend()\n",
    "        ax[index].set_title(i.capitalize())\n",
    "        index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some initial modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Lung Opacity / Not Normal    11083\n",
       "Lung Opacity                     8383\n",
       "Normal                           8071\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Lung Opacity == Pneumonia\n",
    "y_map_3 = { # Normal, Pneumonia, or not normal but not pneumonia\n",
    "    \"Lung Opacity\":1,\n",
    "    \"No Lung Opacity / Not Normal\":0,\n",
    "    \"Normal\":2\n",
    "}\n",
    "\n",
    "y_map_2 = { # Either Pneumonia or Not Pneumonia\n",
    "    \"Lung Opacity\":1,\n",
    "    \"No Lung Opacity / Not Normal\":0,\n",
    "    \"Normal\":0\n",
    "}\n",
    "\n",
    "adult_data = pd.read_csv('../data/adult_patient_data.csv')\n",
    "df_detailed = pd.read_csv('../data/stage_1_detailed_class_info.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Parameters\n",
    "EPOCHS = 20\n",
    "IMAGE_SIZE = (128,128)\n",
    "NUM_IMAGES = 6000 #pic_df.shape[0]\n",
    "CURR_MAP = y_map_2\n",
    "TRAIN_SIZE = 0.8\n",
    "METRICS = ['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Enter DataFrame Construction Function---\n",
      "---Create Pixel Array Labels---\n",
      "---Create Total Pixel Array---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95825352225a4af4873696be6210c306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27537), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/ec2-user/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Create Dataframe---\n",
      "CPU times: user 8min 37s, sys: 15.1 s, total: 8min 52s\n",
      "Wall time: 9min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pic_df = create_pic_df(adult_data, df_detailed=df_detailed, image_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Enter Function---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Modeling---\n",
      "Train on 4800 samples, validate on 1200 samples\n",
      "Epoch 1/20\n",
      "4800/4800 [==============================] - 27s 6ms/step - loss: 0.5733 - acc: 0.7065 - val_loss: 0.4993 - val_acc: 0.7708\n",
      "Epoch 2/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.5299 - acc: 0.7479 - val_loss: 0.4868 - val_acc: 0.7775\n",
      "Epoch 3/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.5079 - acc: 0.7650 - val_loss: 0.5018 - val_acc: 0.7683\n",
      "Epoch 4/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.4975 - acc: 0.7696 - val_loss: 0.4634 - val_acc: 0.7917\n",
      "Epoch 5/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.4709 - acc: 0.7823 - val_loss: 0.4634 - val_acc: 0.7783\n",
      "Epoch 6/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.4558 - acc: 0.7837 - val_loss: 0.4802 - val_acc: 0.7750\n",
      "Epoch 7/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.4486 - acc: 0.7871 - val_loss: 0.4496 - val_acc: 0.7883\n",
      "Epoch 8/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.4371 - acc: 0.7952 - val_loss: 0.4421 - val_acc: 0.7858\n",
      "Epoch 9/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.4220 - acc: 0.8090 - val_loss: 0.4399 - val_acc: 0.7858\n",
      "Epoch 10/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.4224 - acc: 0.8079 - val_loss: 0.4453 - val_acc: 0.7975\n",
      "Epoch 11/20\n",
      "4800/4800 [==============================] - 25s 5ms/step - loss: 0.4062 - acc: 0.8206 - val_loss: 0.4333 - val_acc: 0.7950\n",
      "Epoch 12/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.3932 - acc: 0.8183 - val_loss: 0.4218 - val_acc: 0.8075\n",
      "Epoch 13/20\n",
      "4800/4800 [==============================] - 25s 5ms/step - loss: 0.3813 - acc: 0.8256 - val_loss: 0.4306 - val_acc: 0.8092\n",
      "Epoch 14/20\n",
      "4800/4800 [==============================] - 25s 5ms/step - loss: 0.3660 - acc: 0.8350 - val_loss: 0.4525 - val_acc: 0.8042\n",
      "Epoch 15/20\n",
      "4800/4800 [==============================] - 26s 5ms/step - loss: 0.3489 - acc: 0.8444 - val_loss: 0.4220 - val_acc: 0.8167\n",
      "Epoch 16/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.3316 - acc: 0.8564"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = 'adult_data_2_options'\n",
    "\n",
    "test_model_history, test_model_real, most_recent_model_name = model(pic_df.head(NUM_IMAGES), model_name = model_name, image_size=IMAGE_SIZE, y_map=CURR_MAP, EPOCHS=EPOCHS, train_size = TRAIN_SIZE, metrics = METRICS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "models[most_recent_model_name] = {\n",
    "    'NUM_IMAGES':NUM_IMAGES,\n",
    "    'history':test_model_history,\n",
    "    'EPOCHS':EPOCHS,\n",
    "    'IMAGE_SIZE':IMAGE_SIZE,\n",
    "    'Y_MAP':CURR_MAP,\n",
    "    'TRAIN_SIZE':TRAIN_SIZE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_model(test_model_history, most_recent_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'../data/models/adult_data_3options 2018-10-16 20:49:23.542213.h5': {'NUM_IMAGES': 2000,\n",
       "  'history': <keras.callbacks.History at 0x7f06f81bf7f0>,\n",
       "  'EPOCHS': 2,\n",
       "  'IMAGE_SIZE': (128, 128),\n",
       "  'Y_MAP': {'Lung Opacity': 0,\n",
       "   'No Lung Opacity / Not Normal': 1,\n",
       "   'Normal': 1}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
